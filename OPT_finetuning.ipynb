{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cde69b99-b100-4dbd-999a-f02eef64290e",
   "metadata": {},
   "source": [
    "### Resources for finetuning:\n",
    "https://github.com/huggingface/notebooks/blob/main/examples/language_modeling.ipynb\n",
    " \n",
    "https://github.com/huggingface/notebooks/blob/main/examples/question_answering.ipynb\n",
    "\n",
    "https://github.com/huggingface/transformers/tree/main/notebooks\n",
    "\n",
    "Paper:\n",
    "https://arxiv.org/pdf/2205.01068.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29b578a5-0f93-47f1-835a-b77546429687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'huggingface-cli' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "#notebook_login()\n",
    "!huggingface-cli login\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12b32495-8c73-4db3-822c-2c4d04b13675",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\anaconda3\\envs\\hf\\lib\\site-packages\\huggingface_hub-0.10.1-py3.8.egg\\huggingface_hub\\utils\\_deprecation.py:97: FutureWarning: Deprecated argument(s) used in 'dataset_info': token. Will not be supported from version '0.12'.\n",
      "Found cached dataset pile-of-law (C:/Users/thoma/.cache/huggingface/datasets/pile-of-law___pile-of-law/r_legaladvice/0.0.0/acacf3e29a952ba9026148b979cb438151ebd33f842f5779a213967033c88619)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b89f78113fc84090aed352e6b6073384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"pile-of-law/pile-of-law\",'r_legaladvice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03f0f9d7-db8a-49f4-9085-3f289276c210",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>created_timestamp</th>\n",
       "      <th>downloaded_timestamp</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Title: [TX] Are you liable if someone gets bitten by a wild snake on your property?\\nQuestion:[deleted]\\nAnswer #1: Rob should let his home owners insurance handle itAnswer #2: Texas law is pretty friendly to landowners in these cases.  Specifically see 75.002.\\nhttp://www.statutes.legis.state.tx.us/Docs/CP/htm/CP.75.htm\\n\\nIf Mary's family decided not to take her to the closest hospital, then maybe she should sue them.  Sheesh.Answer #3: Does Mary have dementia? Because it doesn't sound like she was in her right mind. If so, who is in charge of her safety? Answer #4: This sounds like something that happened in like half of my Oregon Trail playthroughs.Answer #5: Like an update on this if anything else happens. Interesting. And I don't think it's a crazy idea for this to be an elaborate insurance scam. People will do some extreme things for the sake of greed. It's hard for normal people to wrap there head around that kind of insanity but it's very real.Answer #6: &amp;gt;They didn't put a tourniquet on it\\n\\nI don't think a tourniquet is appropriate in this situation. They should only be used if there is a chance of the person bleeding to death. Instead, the effected limb should be kept below the heart as much as possible and the person should remain calm to keep their heart from racing and distributing the venom quicker. Then get medical attention as soon as possible.</td>\n",
       "      <td>05-29-2016</td>\n",
       "      <td>11-09-2021</td>\n",
       "      <td>https://www.reddit.com/r/legaladvice/comments/4ll0mu/tx_are_you_liable_if_someone_gets_bitten_by_a/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Title: My father hit a vehicle(s) while driving and drove off without notifying anyone. The police became involved and he wants me to take the fall for it.\\nQuestion:This happened very late at night and shortly after the incident the police were called and through witnesses statements they found our address and visited our home, after some questioning they left but told us that they would be back later after an unsuccessful attempt at getting an answer from my father about who was driving the vehicle at the time of the incident. My father wants me to take the fall for it as he believes I'll receive a lighter punishment than he would as I do not have a full license and only have a learner's license. I am 20 years old and thus an adult and not a minor. This is also in Australia.\\n\\nWhat should I do?\\nAnswer #1: &amp;gt; What should I do?\\n\\nSay no.</td>\n",
       "      <td>11-09-2019</td>\n",
       "      <td>09-25-2021</td>\n",
       "      <td>https://www.reddit.com/r/legaladvice/comments/dtznsx/my_father_hit_a_vehicles_while_driving_and_drove/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Title: Asking my college to change my curriculum for a mental disability?\\nQuestion:Hi everyone.  I feel kind of stuck here. \\n\\n\\n I am a cello performance major at a college in Colorado.  I've also grown up with a number of mental problems including a diagnosis of Tourette Syndrome, which caused a few other problems like bullying and low self esteem indirectly.\\n\\n\\nLast year, I played an awesome Junior recital and now I have to play a Senior recital this year.  \\n\\nThe problem is, the junior recital kind of killed my brain.  After it was all over and the stress was gone, my tourettes were permanently worse.  I also think I might have developed a mild case of insomnia since then, on top of being plagued by suicidal thoughts and depression leading up to the recital and after. I'm worried about what doing a Senior recital, (which is twice as long and grueling to prepare and play) will do to me mentally.  I've already started seeing long-term mental health effects that have yet to go away.  One of the worst tics I've developed is related to the muscles in my bowing arm.\\n\\n\\nDo I have anything to stand on if I want my college to forgo the Senior recital requirement? If I got a doctor's note, who should I bring it to to make this change?\\n\\n My alternate suggestions would be something like a Senior Youtube channel, or other work with the instrument that my cello professor would deem suitable, but would be more doable for someone in my position.  \\n\\n\\nRegardless of how often I want to play in public after graduation, I would really like this degree without destroying what's left of my seemingly fragile mental state.\\n\\nTL;DR-  \\n\\nDo I have grounds to ask for a curriculum change in the last semester of my senior year for my worsening mental disability?  If so, how would I go about it?\\n\\nThanks for any and all help.\\nAnswer #1: I'm sorry you're going through this. I sympathize with your situation. Remember however, accommodations have to be *reasonable*. I would imagine that your senior recital for a *performance major* would be a fairly crucial portion of your degree. You're getting a degree that says you're educated enough to *perform* music as a professional, which would likely entail having to *perform* in public. \\n\\nYou're likely going to have to talk to someone with an ADA specialty. \\n\\n&amp;gt;Regardless of how often I want to play in public after graduation, I would really like this degree without destroying what's left of my seemingly fragile mental state.\\n\\nI don't mean to sound harsh here, but is it really worth it. If you're harming yourself mentally, what good is a degree that you're going to be seriously limited in what you can do with it? Do you plan on using this degree to procure a degree, or are you doing it because you love playing and it's not something you're going to pursue? If i's the latter, I would probably suggest that you consider switching majors. College isn't cheap and paying it back for years afterwards with a degree you can't use, might hurt you in the long run and cause you even more mental stress.\\n\\nI hope you the best of luck in whatever decision you make. \\nAnswer #2: So you are a performance major who wants to graduate without performing?</td>\n",
       "      <td>12-05-2017</td>\n",
       "      <td>10-01-2021</td>\n",
       "      <td>https://www.reddit.com/r/legaladvice/comments/7hqt9o/asking_my_college_to_change_my_curriculum_for_a/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Title: How high is the success rate of representing yourself in court?\\nQuestion:[This was my initial post](https://www.reddit.com/r/legaladvice/comments/8t5yko/21_year_old_with_upcoming_hearing_for_restraining/)\\n\\nIt’s not appearing to be very likely that I’ll be able to afford a lawyer in time for the hearing, but I don’t want to just not show up because I know I’m innocent &amp;amp; I won’t be able to make it a whole year without my son. Are there any more affordable alternatives? I live in smalltown South Dakota so lawyers are very limited &amp;amp; they all want basically the same amount, $1200 give or take a hundred. Between tuition, bills, etc I can’t scrap up the money by mid July. \\n\\nDo I have ANY chance at fighting a restraining order by myself, versus her, her family, &amp;amp; her lawyer? Like I said in my first post, I can’t really present anything to prove that I’m not psychotic or worthy of a restraining order. At the same time, her evidence is pretty weak, sighting just a few of the text messages when we’d argue &amp;amp; some of my consecutive phone calls when she’d leave with the baby unannounced.\\n\\nIs it likely for the judge to actually hear me out, or will I basically be dismissed automatically when I show up without a lawyer. This is my first time in court so I’m not familiar with much of anything. Anything helps. Thanks.\\nAnswer #1: The advice hasn't changed since you first posted this. Nobody can give you any odds. There are too many factors.  They mere fact you are asking this suggests you lack experience to do this on your own.</td>\n",
       "      <td>06-23-2018</td>\n",
       "      <td>09-30-2021</td>\n",
       "      <td>https://www.reddit.com/r/legaladvice/comments/8tb0np/how_high_is_the_success_rate_of_representing/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Title: OCS Denying Rights to Practice Religion\\nQuestion:The situation is extremely complicated - but to try to keep it simple:\\n\\nOCS is requiring my wife and I to NOT attend our church if my wife's daughter is there. They say we are not allowed to be in contact within the \"community\" or in public. \\n\\nThis is just ONE of MANY things OCS is doing to my wife. They have no accountability. They are literally trying to control our lives.\\n\\nThe question I have is: is it legal for a State (AK) agency to dictate where/when we and our daughter practice religion?\\n\\nMany thanks in advance. There may be many other questions that arise - they are doing some really shady stuff.\\nAnswer #1: If they made an order that extreme there is a reason. \\n\\nBut yes they can. They are not denying you the right to tactics your religion you just can't be in contact with the child. So go at a different time or find a new church.</td>\n",
       "      <td>02-14-2017</td>\n",
       "      <td>11-08-2021</td>\n",
       "      <td>https://www.reddit.com/r/legaladvice/comments/5u3kev/ocs_denying_rights_to_practice_religion/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Title: Mistreatment at work, using cruelty to get someone to quit, legal or not?\\nQuestion:[deleted]\\nAnswer #1: &amp;gt; Am I right in thinking that the mistreatment through receiving excess work, use of harsh tones and facial expressions, and behaviors implying rudeness and hostility is illegal in the work place?\\n\\nNope. Answer #2: No, you are not correct. It's perfectly legal to be rude, obnoxious, and even unfair. A \"hostile workplace\" is when mistreatment is based on membership in a protected class and you have given no reason to assume that is the case here.Answer #3: &amp;gt; Am I right in thinking that the mistreatment through receiving excess work, use of harsh tones and facial expressions, and behaviors implying rudeness and hostility is illegal in the work place?\\n\\nNo. \\n\\n&amp;gt; I personally feel obligated to act.\\n\\nWhich will get her IMMEDIATELY fired and/or you jailed.\\n\\nIt is not illegal to be a jerk of a boss. Answer #4: Being a terrible/mean person is not illegal. Answer #5: You think being mean/rude is illegal? Seriously? Answer #6: You are probably wrong. but without a location impossible to say.</td>\n",
       "      <td>10-22-2017</td>\n",
       "      <td>10-01-2021</td>\n",
       "      <td>https://www.reddit.com/r/legaladvice/comments/785be6/mistreatment_at_work_using_cruelty_to_get_someone/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Title: Someone might be trying to use me for tax fraud.\\nQuestion:First off, I'm located in Kentucky and I'm trying to make some extra side money. Well, a friend of a friend has offered to pay me $500 a day to do some work for him for his business. The only catch is, he wants to pay me with a $1500 check every time and I am to cash it and give him back $1000. I could really use the extra money but this sounds a little sketchy. He won't go into much detail about why he wants to pay me like this but I assume he's wanting to write off extra Business expense. He swears up and down I have nothing to worry about as long as I cash it and don't deposit it. \\n\\nI would like some advice on the matter if I were to go through with this deal for a few months. What could the repercussions be on me? Is this something that is fine legally and I'm just overthinking it? \\nAnswer #1: This is 100% a scam. It can go one of two ways: You cash the check at your bank and give him his cut of the money. Once the check bounces (and it WILL), the bank will remove the $1500 from your account along with bounced check fees.\\n\\n\\nIf you cash it somewhere like Walmart, you could be subject to criminal charges. They take down all your info, it's not hard to find you after the check bounces.\\n\\n\\nThis could also be a part of a money laundering scheme, which you REALLY don't want to get tangled up in. Unless the idea of prison time amuses you.Answer #2: Btw you need new friendsAnswer #3: I am not a lawyer.  It sounds like the fake check scam.  That could land you in both legal and financial trouble.  Don't do it.  And avoid any further contact with this person.</td>\n",
       "      <td>03-01-2017</td>\n",
       "      <td>11-08-2021</td>\n",
       "      <td>https://www.reddit.com/r/legaladvice/comments/5wwq8g/someone_might_be_trying_to_use_me_for_tax_fraud/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Title: [Florida] please don't delete we're not a troll I promise but we need advice\\nQuestion:[removed]\\nAnswer #1: This post can be used against you as well in a wrongful death suit as evidence that you delayed calling for help to make sure you could protect yourself first.</td>\n",
       "      <td>10-19-2017</td>\n",
       "      <td>10-01-2021</td>\n",
       "      <td>https://www.reddit.com/r/legaladvice/comments/77g5nz/florida_please_dont_delete_were_not_a_troll_i/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Title: Why is the legal system so screwed up?\\nQuestion:I am involved in my first legal dispute and it is ruining my life. Long story short, I have a crazy/creepy neighbor that has been harassing me for the last 5 years. Two years ago, I tried to sell my condo to get away from him and he made attempts to interfere with the sale. Because of this, I took my condo off the market for 6 months and then re-listed it for sale without a for sale sign in hopes that I could sell it without him finding out.  After a few weeks, I got an offer on my place and it went under contract. My crazy neighbor found out, quickly filed a frivolous lawsuit against my hoa, me, and my boyfriend; called my real estate agent (he is also a realtor), and told my agent that my hoa was being sued so they need to notify my buyer. Because of the frivolous suit, my buyers lender pulled out and my sale fell through again. \\n\\nI ended up having to spend thousands of dollars hiring an attorney to defend both myself and my boyfriend- and ultimately get his BS claims against us dropped, and then I countersued him for intentionally interfering with my contract. My lawyer says that I basically have a great case and will likely win, but it is going to cost a fortune to go to trial. \\n\\nI am only 27 years old and I don’t have a ton of money to see this through. My lawyer has been doing the best she can to save me money but the crazy neighbor’s lawyer is doing everything he can to rack up my bills in hopes that I will drop the case. He refuses to settle with me and keeps doing really ass-holey things like scheduling mediation and then saying he won’t mediate with me after I get there. He even got paid off by the hoa’s insurance company despite his case not having any merit so he is being rewarded for his shitty behavior. \\n\\nI don’t understand why the legal system allows this type of behavior and also makes it so incredibly expensive to where normal people can never attain justice. \\n\\nWhat would you do in this situation? I am afraid that even if I drop the suit, he will keep interfering in my sale and will never leave me alone. I am able and willing to deal with all aspects of the lawsuit stress-wise, I just don’t think I have the money for trial. \\n\\n\\nAnswer #1: You have an HOA, have you tried to get it to push back on him?</td>\n",
       "      <td>06-17-2018</td>\n",
       "      <td>09-30-2021</td>\n",
       "      <td>https://www.reddit.com/r/legaladvice/comments/8ruey5/why_is_the_legal_system_so_screwed_up/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Title: Caught shoplifting from Walmart, spent most of my night in jail. Looking for any advice\\nQuestion:Yesterday I (22m) was caught shoplifting from Walmart. I had tried to take some food, and a couple small electronics. My total was 120 and they made the decision and cops were called. I was handcuffed and sent downtown where i spent 9 hours before being released with a bond of $1000 and a court date on August 27th. This is my first ever offense and I’m freaking out and have no idea where to go. I called a few lawyers this morning but they say they charge upwards of 1500 for their fee. I really don’t have the money for that kind of thing and that really defeats the purpose to me since my bond is cheaper. If anyone has any ideas or advice, i would greatly appreciate it\\nAnswer #1: Don't talk to the cops, go to your first court date, plead not guilty and ask for a public defender.</td>\n",
       "      <td>08-01-2018</td>\n",
       "      <td>09-29-2021</td>\n",
       "      <td>https://www.reddit.com/r/legaladvice/comments/93pc5t/caught_shoplifting_from_walmart_spent_most_of_my/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import ClassLabel\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))\n",
    "show_random_elements(dataset[\"train\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b009d700-0109-4cb7-a2ac-4c3acc523073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-125m\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-125m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9eba3d0f-e9fe-4923-bdc0-e382271523fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17064e5a-f5f2-4897-aec4-3737ffb00ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Title: Personal information and walmart\\nQuestion:This is whats going on. I bought a nerf gun for my son at Wal-Mart for Christmas. I found the same nerf gun $40 cheaper, so naturally returned it to Wal-Mart. I got a call yesterday (well voicemail) from a Wal-Mart customer who bought the nerf gun.. it gets weird here.. they said Wal-Mart put my personal information on the box and decided to use it to contact me to see if there is anything wrong with it. I am naturally paranoid with my personal information as is most people. Why would they do this? What should I do? sorry if I am in the wrong sub-reddit.. Thanks in advance \\n\\np.s. I do not frequent Wal-Mart often, it was the only place for this particular nerf gun at the moment \\n\\nI am in the chicago area \\nAnswer #1: Your information is personal in nature, but is by no means private.  Your full name, birth date, home address, and sometimes phone numbers are all generally a matter of public record and readily available to anyone who wants them.\\n\\nIt may be weird, but I don't believe it to be illegal.  You can choose to answer or not answer their questions, and you can tell them to not contact you about the Nerf gun in the future.\",\n",
       " 'created_timestamp': '01-10-2018',\n",
       " 'downloaded_timestamp': '10-01-2021',\n",
       " 'url': 'https://www.reddit.com/r/legaladvice/comments/7phbeu/personal_information_and_walmart/'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][161]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf497114-5bb5-4bb3-8938-03eaca375bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 46525, 35, 13129, 335, 8, 21788, 15964, 50118, 45641, 35, 713, 16, 45676, 164, 15, 4, 38, 2162, 10, 38286, 506, 1751, 13, 127, 979, 23, 6092, 12, 13012, 13, 1619, 4, 38, 303, 5, 276, 38286, 506, 1751, 68, 1749, 7246, 6, 98, 8366, 1835, 24, 7, 6092, 12, 13012, 4, 38, 300, 10, 486, 2350, 36, 3056, 30118, 10555, 43, 31, 10, 6092, 12, 13012, 2111, 54, 2162, 5, 38286, 506, 1751, 7586, 24, 1516, 7735, 259, 7586, 51, 26, 6092, 12, 13012, 342, 127, 1081, 335, 15, 5, 2233, 8, 1276, 7, 304, 24, 7, 1511, 162, 7, 192, 114, 89, 16, 932, 1593, 19, 24, 4, 38, 524, 8366, 33554, 19, 127, 1081, 335, 25, 16, 144, 82, 4, 2612, 74, 51, 109, 42, 116, 653, 197, 38, 109, 116, 6661, 114, 38, 524, 11, 5, 1593, 2849, 12, 48724, 7586, 4557, 11, 3316, 1437, 50118, 50118, 642, 4, 29, 4, 38, 109, 45, 7690, 6092, 12, 13012, 747, 6, 24, 21, 5, 129, 317, 13, 42, 1989, 38286, 506, 1751, 23, 5, 1151, 1437, 50118, 50118, 100, 524, 11, 5, 1855, 42938, 443, 1437, 50118, 33683, 849, 134, 35, 2486, 335, 16, 1081, 11, 2574, 6, 53, 16, 30, 117, 839, 940, 4, 1437, 2486, 455, 766, 6, 3113, 1248, 6, 184, 1100, 6, 8, 2128, 1028, 1530, 32, 70, 3489, 10, 948, 9, 285, 638, 8, 16650, 577, 7, 1268, 54, 1072, 106, 4, 50118, 50118, 243, 189, 28, 7735, 6, 53, 38, 218, 75, 679, 24, 7, 28, 2439, 4, 1437, 370, 64, 2807, 7, 1948, 50, 45, 1948, 49, 1142, 6, 8, 47, 64, 1137, 106, 7, 45, 1511, 47, 59, 5, 24579, 506, 1751, 11, 5, 499, 4], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_function(dataset[\"train\"][161])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "604e9e1c-088a-47b1-a044-6286618a636a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:/Users/thoma/.cache/huggingface/datasets/pile-of-law___pile-of-law/r_legaladvice/0.0.0/acacf3e29a952ba9026148b979cb438151ebd33f842f5779a213967033c88619\\cache-3bcde4656ba684b1.arrow\n",
      "Loading cached processed dataset at C:/Users/thoma/.cache/huggingface/datasets/pile-of-law___pile-of-law/r_legaladvice/0.0.0/acacf3e29a952ba9026148b979cb438151ebd33f842f5779a213967033c88619\\cache-d3ffc92b6cd8bfa1.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_function, batched=True, num_proc=1, remove_columns=[\"text\",\"created_timestamp\",\"downloaded_timestamp\",\"url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2789efa7-61b6-45c1-a6a9-51dbe2ced65f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2,\n",
       "  46525,\n",
       "  35,\n",
       "  38,\n",
       "  206,\n",
       "  951,\n",
       "  16,\n",
       "  3433,\n",
       "  88,\n",
       "  127,\n",
       "  512,\n",
       "  7,\n",
       "  120,\n",
       "  13543,\n",
       "  13,\n",
       "  162,\n",
       "  145,\n",
       "  10,\n",
       "  1099,\n",
       "  1393,\n",
       "  411,\n",
       "  377,\n",
       "  536,\n",
       "  50118,\n",
       "  45641,\n",
       "  35,\n",
       "  713,\n",
       "  16,\n",
       "  11,\n",
       "  2042,\n",
       "  4,\n",
       "  3727,\n",
       "  11,\n",
       "  392,\n",
       "  6,\n",
       "  38,\n",
       "  13636,\n",
       "  4024,\n",
       "  5,\n",
       "  1593,\n",
       "  169,\n",
       "  159,\n",
       "  10,\n",
       "  5342,\n",
       "  3610,\n",
       "  65,\n",
       "  169,\n",
       "  921,\n",
       "  142,\n",
       "  38,\n",
       "  56,\n",
       "  45,\n",
       "  551,\n",
       "  127,\n",
       "  33286,\n",
       "  5679,\n",
       "  29,\n",
       "  14,\n",
       "  183,\n",
       "  4,\n",
       "  17397,\n",
       "  117,\n",
       "  1677,\n",
       "  58,\n",
       "  567,\n",
       "  1567,\n",
       "  162,\n",
       "  8,\n",
       "  25,\n",
       "  1010,\n",
       "  25,\n",
       "  38,\n",
       "  5426,\n",
       "  24,\n",
       "  6,\n",
       "  38,\n",
       "  4024,\n",
       "  11,\n",
       "  5,\n",
       "  4806,\n",
       "  6625,\n",
       "  13,\n",
       "  5,\n",
       "  1079,\n",
       "  9,\n",
       "  5,\n",
       "  1803,\n",
       "  454,\n",
       "  38,\n",
       "  115,\n",
       "  1004,\n",
       "  4,\n",
       "  38,\n",
       "  21,\n",
       "  2198,\n",
       "  7619,\n",
       "  8435,\n",
       "  66,\n",
       "  59,\n",
       "  24,\n",
       "  6,\n",
       "  98,\n",
       "  38,\n",
       "  1276,\n",
       "  7,\n",
       "  213,\n",
       "  124,\n",
       "  184,\n",
       "  8,\n",
       "  38003,\n",
       "  2185,\n",
       "  4,\n",
       "  38,\n",
       "  1299,\n",
       "  3668,\n",
       "  6587,\n",
       "  59,\n",
       "  24,\n",
       "  4,\n",
       "  287,\n",
       "  38,\n",
       "  21,\n",
       "  1428,\n",
       "  184,\n",
       "  6,\n",
       "  38,\n",
       "  5324,\n",
       "  10,\n",
       "  512,\n",
       "  511,\n",
       "  162,\n",
       "  4,\n",
       "  38,\n",
       "  554,\n",
       "  7,\n",
       "  185,\n",
       "  124,\n",
       "  3197,\n",
       "  8,\n",
       "  1076,\n",
       "  21242,\n",
       "  7,\n",
       "  860,\n",
       "  7,\n",
       "  2217,\n",
       "  123,\n",
       "  13,\n",
       "  59,\n",
       "  379,\n",
       "  728,\n",
       "  6,\n",
       "  53,\n",
       "  38,\n",
       "  1705,\n",
       "  17,\n",
       "  27,\n",
       "  90,\n",
       "  4,\n",
       "  152,\n",
       "  7619,\n",
       "  8435,\n",
       "  162,\n",
       "  66,\n",
       "  190,\n",
       "  55,\n",
       "  8,\n",
       "  38,\n",
       "  1299,\n",
       "  101,\n",
       "  38,\n",
       "  21,\n",
       "  350,\n",
       "  16573,\n",
       "  7,\n",
       "  1305,\n",
       "  6,\n",
       "  98,\n",
       "  38,\n",
       "  1276,\n",
       "  7,\n",
       "  4757,\n",
       "  19,\n",
       "  5,\n",
       "  563,\n",
       "  8,\n",
       "  213,\n",
       "  184,\n",
       "  4,\n",
       "  287,\n",
       "  1010,\n",
       "  25,\n",
       "  38,\n",
       "  300,\n",
       "  66,\n",
       "  9,\n",
       "  127,\n",
       "  512,\n",
       "  6,\n",
       "  37,\n",
       "  2468,\n",
       "  62,\n",
       "  220,\n",
       "  7,\n",
       "  162,\n",
       "  6,\n",
       "  6387,\n",
       "  159,\n",
       "  39,\n",
       "  2931,\n",
       "  6,\n",
       "  8,\n",
       "  554,\n",
       "  11347,\n",
       "  23,\n",
       "  162,\n",
       "  4,\n",
       "  91,\n",
       "  21,\n",
       "  740,\n",
       "  4781,\n",
       "  154,\n",
       "  162,\n",
       "  66,\n",
       "  6,\n",
       "  2758,\n",
       "  162,\n",
       "  7,\n",
       "  213,\n",
       "  3549,\n",
       "  2185,\n",
       "  6,\n",
       "  8,\n",
       "  5608,\n",
       "  162,\n",
       "  4,\n",
       "  85,\n",
       "  21,\n",
       "  169,\n",
       "  375,\n",
       "  2340,\n",
       "  921,\n",
       "  14706,\n",
       "  4,\n",
       "  38,\n",
       "  399,\n",
       "  17,\n",
       "  27,\n",
       "  90,\n",
       "  224,\n",
       "  932,\n",
       "  8,\n",
       "  95,\n",
       "  3203,\n",
       "  88,\n",
       "  127,\n",
       "  2632,\n",
       "  4,\n",
       "  6068,\n",
       "  14,\n",
       "  37,\n",
       "  115,\n",
       "  45,\n",
       "  33,\n",
       "  684,\n",
       "  61,\n",
       "  3537,\n",
       "  38,\n",
       "  21,\n",
       "  11,\n",
       "  6,\n",
       "  3680,\n",
       "  38,\n",
       "  1979,\n",
       "  17,\n",
       "  27,\n",
       "  90,\n",
       "  33,\n",
       "  1613,\n",
       "  1025,\n",
       "  4,\n",
       "  38,\n",
       "  4711,\n",
       "  89,\n",
       "  13,\n",
       "  59,\n",
       "  389,\n",
       "  12,\n",
       "  1898,\n",
       "  728,\n",
       "  4,\n",
       "  38,\n",
       "  376,\n",
       "  124,\n",
       "  66,\n",
       "  8,\n",
       "  300,\n",
       "  11,\n",
       "  127,\n",
       "  512,\n",
       "  456,\n",
       "  6,\n",
       "  172,\n",
       "  554,\n",
       "  1428,\n",
       "  4,\n",
       "  38,\n",
       "  794,\n",
       "  14,\n",
       "  37,\n",
       "  56,\n",
       "  2294,\n",
       "  11,\n",
       "  41,\n",
       "  18743,\n",
       "  8,\n",
       "  56,\n",
       "  9010,\n",
       "  13,\n",
       "  162,\n",
       "  4,\n",
       "  91,\n",
       "  880,\n",
       "  7,\n",
       "  1407,\n",
       "  162,\n",
       "  456,\n",
       "  4,\n",
       "  38,\n",
       "  21,\n",
       "  441,\n",
       "  7,\n",
       "  2217,\n",
       "  123,\n",
       "  8,\n",
       "  7433,\n",
       "  127,\n",
       "  512,\n",
       "  639,\n",
       "  10,\n",
       "  745,\n",
       "  147,\n",
       "  37,\n",
       "  1705,\n",
       "  17,\n",
       "  27,\n",
       "  90,\n",
       "  465,\n",
       "  162,\n",
       "  4,\n",
       "  1437,\n",
       "  50118,\n",
       "  50118,\n",
       "  35515,\n",
       "  556,\n",
       "  7,\n",
       "  5,\n",
       "  253,\n",
       "  9,\n",
       "  550,\n",
       "  4,\n",
       "  38,\n",
       "  21,\n",
       "  602,\n",
       "  10,\n",
       "  1805,\n",
       "  66,\n",
       "  9,\n",
       "  5,\n",
       "  247,\n",
       "  8,\n",
       "  5,\n",
       "  363,\n",
       "  137,\n",
       "  38,\n",
       "  314,\n",
       "  38,\n",
       "  362,\n",
       "  65,\n",
       "  9,\n",
       "  127,\n",
       "  3235,\n",
       "  28162,\n",
       "  66,\n",
       "  7,\n",
       "  127,\n",
       "  512,\n",
       "  4,\n",
       "  38,\n",
       "  524,\n",
       "  29206,\n",
       "  2068,\n",
       "  10002,\n",
       "  38,\n",
       "  5930,\n",
       "  127,\n",
       "  1883,\n",
       "  4,\n",
       "  520,\n",
       "  38,\n",
       "  439,\n",
       "  66,\n",
       "  419,\n",
       "  5,\n",
       "  220,\n",
       "  662,\n",
       "  6,\n",
       "  5,\n",
       "  1393,\n",
       "  1883,\n",
       "  21,\n",
       "  1810,\n",
       "  490,\n",
       "  19,\n",
       "  5,\n",
       "  512,\n",
       "  2664,\n",
       "  9512,\n",
       "  4,\n",
       "  20,\n",
       "  28441,\n",
       "  6,\n",
       "  19015,\n",
       "  2233,\n",
       "  6,\n",
       "  8,\n",
       "  12304,\n",
       "  58,\n",
       "  12961,\n",
       "  6128,\n",
       "  6,\n",
       "  8,\n",
       "  5,\n",
       "  14016,\n",
       "  4328,\n",
       "  857,\n",
       "  21,\n",
       "  12256,\n",
       "  4102,\n",
       "  4,\n",
       "  85,\n",
       "  21,\n",
       "  1099,\n",
       "  615,\n",
       "  14,\n",
       "  24,\n",
       "  2551,\n",
       "  101,\n",
       "  51,\n",
       "  56,\n",
       "  1240,\n",
       "  1823,\n",
       "  86,\n",
       "  442,\n",
       "  686,\n",
       "  5,\n",
       "  512,\n",
       "  21,\n",
       "  10,\n",
       "  4463,\n",
       "  4,\n",
       "  345,\n",
       "  21,\n",
       "  1085,\n",
       "  5130,\n",
       "  8,\n",
       "  70,\n",
       "  14,\n",
       "  21,\n",
       "  551,\n",
       "  21,\n",
       "  127,\n",
       "  17637,\n",
       "  510,\n",
       "  20529,\n",
       "  6,\n",
       "  103,\n",
       "  14967,\n",
       "  6,\n",
       "  10,\n",
       "  6036,\n",
       "  29,\n",
       "  4085,\n",
       "  1886,\n",
       "  6,\n",
       "  8,\n",
       "  10,\n",
       "  2003,\n",
       "  9,\n",
       "  13938,\n",
       "  4,\n",
       "  1308,\n",
       "  68,\n",
       "  2619,\n",
       "  1690,\n",
       "  4774,\n",
       "  31468,\n",
       "  21,\n",
       "  314,\n",
       "  639,\n",
       "  4,\n",
       "  252,\n",
       "  314,\n",
       "  10,\n",
       "  6356,\n",
       "  9,\n",
       "  14407,\n",
       "  8,\n",
       "  10,\n",
       "  13026,\n",
       "  15,\n",
       "  5,\n",
       "  2377,\n",
       "  2418,\n",
       "  4,\n",
       "  440,\n",
       "  97,\n",
       "  1677,\n",
       "  58,\n",
       "  3187,\n",
       "  88,\n",
       "  4,\n",
       "  38,\n",
       "  222,\n",
       "  486,\n",
       "  5,\n",
       "  249,\n",
       "  6,\n",
       "  8,\n",
       "  9010,\n",
       "  41,\n",
       "  1946,\n",
       "  13,\n",
       "  106,\n",
       "  6,\n",
       "  53,\n",
       "  38,\n",
       "  956,\n",
       "  7,\n",
       "  989,\n",
       "  98,\n",
       "  38,\n",
       "  56,\n",
       "  7,\n",
       "  10061,\n",
       "  5,\n",
       "  486,\n",
       "  4,\n",
       "  598,\n",
       "  162,\n",
       "  6,\n",
       "  89,\n",
       "  21,\n",
       "  1085,\n",
       "  2422,\n",
       "  7775,\n",
       "  59,\n",
       "  24,\n",
       "  4,\n",
       "  85,\n",
       "  156,\n",
       "  1472,\n",
       "  1782,\n",
       "  25,\n",
       "  89,\n",
       "  21,\n",
       "  10,\n",
       "  28441,\n",
       "  11,\n",
       "  5,\n",
       "  124,\n",
       "  11517,\n",
       "  4,\n",
       "  635,\n",
       "  6,\n",
       "  127,\n",
       "  512,\n",
       "  21,\n",
       "  5,\n",
       "  129,\n",
       "  65,\n",
       "  11,\n",
       "  5,\n",
       "  319,\n",
       "  14,\n",
       "  115,\n",
       "  28,\n",
       "  450,\n",
       "  31,\n",
       "  5,\n",
       "  921,\n",
       "  6,\n",
       "  98,\n",
       "  24,\n",
       "  21,\n",
       "  10,\n",
       "  828,\n",
       "  7782,\n",
       "  14,\n",
       "  51,\n",
       "  4689,\n",
       "  127,\n",
       "  512,\n",
       "  4,\n",
       "  6811,\n",
       "  38,\n",
       "  2967,\n",
       "  14,\n",
       "  127,\n",
       "  2632,\n",
       "  473,\n",
       "  33,\n",
       "  573,\n",
       "  4387,\n",
       "  6,\n",
       "  53,\n",
       "  30,\n",
       "  172,\n",
       "  24,\n",
       "  21,\n",
       "  350,\n",
       "  628,\n",
       "  8,\n",
       "  51,\n",
       "  117,\n",
       "  1181,\n",
       "  56,\n",
       "  5,\n",
       "  4338,\n",
       "  4,\n",
       "  1308,\n",
       "  19812,\n",
       "  174,\n",
       "  162,\n",
       "  14,\n",
       "  117,\n",
       "  512,\n",
       "  34,\n",
       "  655,\n",
       "  57,\n",
       "  3187,\n",
       "  88,\n",
       "  11,\n",
       "  14,\n",
       "  319,\n",
       "  4,\n",
       "  38,\n",
       "  21,\n",
       "  1613,\n",
       "  13,\n",
       "  10,\n",
       "  353,\n",
       "  8,\n",
       "  127,\n",
       "  512,\n",
       "  21,\n",
       "  45,\n",
       "  89,\n",
       "  148,\n",
       "  14,\n",
       "  86,\n",
       "  4,\n",
       "  1437,\n",
       "  50118,\n",
       "  50118,\n",
       "  35515,\n",
       "  556,\n",
       "  7,\n",
       "  452,\n",
       "  4,\n",
       "  38,\n",
       "  439,\n",
       "  66,\n",
       "  42,\n",
       "  662,\n",
       "  8,\n",
       "  5426,\n",
       "  127,\n",
       "  512,\n",
       "  56,\n",
       "  57,\n",
       "  3187,\n",
       "  88,\n",
       "  456,\n",
       "  4,\n",
       "  7574,\n",
       "  6,\n",
       "  38,\n",
       "  56,\n",
       "  5930,\n",
       "  24,\n",
       "  6,\n",
       "  53,\n",
       "  42,\n",
       "  86,\n",
       "  5,\n",
       "  4408,\n",
       "  1883,\n",
       "  21,\n",
       "  1759,\n",
       "  5686,\n",
       "  490,\n",
       "  4,\n",
       "  345,\n",
       "  21,\n",
       "  3668,\n",
       "  1085,\n",
       "  11,\n",
       "  5,\n",
       "  512,\n",
       "  14,\n",
       "  74,\n",
       "  492,\n",
       "  951,\n",
       "  10,\n",
       "  1219,\n",
       "  7,\n",
       "  1108,\n",
       "  11,\n",
       "  4,\n",
       "  20,\n",
       "  1312,\n",
       "  12304,\n",
       "  8,\n",
       "  19015,\n",
       "  2233,\n",
       "  58,\n",
       "  314,\n",
       "  490,\n",
       "  4,\n",
       "  20,\n",
       "  14407,\n",
       "  314,\n",
       "  639,\n",
       "  94,\n",
       "  86,\n",
       "  58,\n",
       "  202,\n",
       "  11,\n",
       "  5,\n",
       "  12304,\n",
       "  4,\n",
       "  10385,\n",
       "  21,\n",
       "  551,\n",
       "  8,\n",
       "  117,\n",
       "  97,\n",
       "  1677,\n",
       "  58,\n",
       "  3187,\n",
       "  88,\n",
       "  4,\n",
       "  653,\n",
       "  21,\n",
       "  7775,\n",
       "  7,\n",
       "  162,\n",
       "  21,\n",
       "  14,\n",
       "  114,\n",
       "  51,\n",
       "  74,\n",
       "  33,\n",
       "  1367,\n",
       "  5,\n",
       "  12304,\n",
       "  6,\n",
       "  19015,\n",
       "  2233,\n",
       "  6,\n",
       "  8,\n",
       "  1883,\n",
       "  6,\n",
       "  38,\n",
       "  74,\n",
       "  33,\n",
       "  56,\n",
       "  117,\n",
       "  1114,\n",
       "  24,\n",
       "  21,\n",
       "  3187,\n",
       "  88,\n",
       "  4,\n",
       "  1437,\n",
       "  50118,\n",
       "  50118,\n",
       "  100,\n",
       "  33,\n",
       "  20208,\n",
       "  127,\n",
       "  2900,\n",
       "  8,\n",
       "  38,\n",
       "  1395,\n",
       "  206,\n",
       "  9,\n",
       "  1268,\n",
       "  1493,\n",
       "  14,\n",
       "  115,\n",
       "  28,\n",
       "  608,\n",
       "  42,\n",
       "  8,\n",
       "  24,\n",
       "  630,\n",
       "  75,\n",
       "  2045,\n",
       "  101,\n",
       "  10,\n",
       "  21279,\n",
       "  14,\n",
       "  42,\n",
       "  1102,\n",
       "  2330,\n",
       "  11,\n",
       "  2230,\n",
       "  5,\n",
       "  276,\n",
       "  169,\n",
       "  4,\n",
       "  29175,\n",
       "  14,\n",
       "  951,\n",
       "  16,\n",
       "  888,\n",
       "  42,\n",
       "  5373,\n",
       "  6,\n",
       "  16,\n",
       "  89,\n",
       "  143,\n",
       "  1030,\n",
       "  814,\n",
       "  14,\n",
       "  38,\n",
       "  64,\n",
       "  185,\n",
       "  116,\n",
       "  345,\n",
       "  16,\n",
       "  9261,\n",
       "  1493,\n",
       "  14,\n",
       "  38,\n",
       "  64,\n",
       "  2221,\n",
       "  127,\n",
       "  512,\n",
       "  4,\n",
       "  318,\n",
       "  38,\n",
       "  192,\n",
       "  5,\n",
       "  573,\n",
       "  4338,\n",
       "  8,\n",
       "  38,\n",
       "  524,\n",
       "  441,\n",
       "  7,\n",
       "  3058,\n",
       "  114,\n",
       "  24,\n",
       "  16,\n",
       "  123,\n",
       "  6,\n",
       "  99,\n",
       "  64,\n",
       "  38,\n",
       "  109,\n",
       "  7,\n",
       "  912,\n",
       "  42,\n",
       "  31,\n",
       "  2909,\n",
       "  456,\n",
       "  116,\n",
       "  404,\n",
       "  38,\n",
       "  216,\n",
       "  16,\n",
       "  99,\n",
       "  37,\n",
       "  1326,\n",
       "  101,\n",
       "  36,\n",
       "  700,\n",
       "  56,\n",
       "  11693,\n",
       "  21462,\n",
       "  43,\n",
       "  8,\n",
       "  14,\n",
       "  37,\n",
       "  6790,\n",
       "  10,\n",
       "  4334,\n",
       "  15283,\n",
       "  4,\n",
       "  38,\n",
       "  218,\n",
       "  75,\n",
       "  216,\n",
       "  39,\n",
       "  766,\n",
       "  8,\n",
       "  25,\n",
       "  444,\n",
       "  25,\n",
       "  38,\n",
       "  216,\n",
       "  37,\n",
       "  473,\n",
       "  45,\n",
       "  216,\n",
       "  99,\n",
       "  127,\n",
       "  766,\n",
       "  16,\n",
       "  50,\n",
       "  127,\n",
       "  3537,\n",
       "  346,\n",
       "  4,\n",
       "  1437,\n",
       "  50118,\n",
       "  33683,\n",
       "  849,\n",
       "  134,\n",
       "  35,\n",
       "  8655,\n",
       "  10,\n",
       "  249,\n",
       "  266,\n",
       "  13,\n",
       "  358,\n",
       "  1108,\n",
       "  11,\n",
       "  8,\n",
       "  120,\n",
       "  10,\n",
       "  12575,\n",
       "  11021,\n",
       "  4,\n",
       "  38,\n",
       "  206,\n",
       "  47,\n",
       "  17,\n",
       "  27,\n",
       "  241,\n",
       "  2542,\n",
       "  14,\n",
       "  5,\n",
       "  249,\n",
       "  351,\n",
       "  17,\n",
       "  27,\n",
       "  90,\n",
       "  533,\n",
       "  28,\n",
       "  441,\n",
       "  7,\n",
       "  3094,\n",
       "  54,\n",
       "  5,\n",
       "  14542,\n",
       "  16,\n",
       "  31,\n",
       "  10,\n",
       "  1345,\n",
       "  8,\n",
       "  8194,\n",
       "  9,\n",
       "  5,\n",
       "  512,\n",
       "  103,\n",
       "  801,\n",
       "  1984,\n",
       "  4024,\n",
       "  14,\n",
       "  183,\n",
       "  4,\n",
       "  497,\n",
       "  275,\n",
       "  6,\n",
       "  114,\n",
       "  47,\n",
       "  386,\n",
       "  122,\n",
       "  8,\n",
       "  42,\n",
       "  1388,\n",
       "  2909,\n",
       "  6,\n",
       "  2085,\n",
       "  47,\n",
       "  64,\n",
       "  33172,\n",
       "  ...],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  ...]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[\"train\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "958bb934-3644-4555-ab82-b77163b1a984",
   "metadata": {},
   "outputs": [],
   "source": [
    "#block_size = tokenizer.model_max_length\n",
    "block_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0fbea33-b914-47c0-8052-19761da86565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "        # customize this part to your needs.\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51992ed7-ee09-4add-b5ce-3cb5fe1a9a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:/Users/thoma/.cache/huggingface/datasets/pile-of-law___pile-of-law/r_legaladvice/0.0.0/acacf3e29a952ba9026148b979cb438151ebd33f842f5779a213967033c88619\\cache-2f4e3edc68f1dc89.arrow\n",
      "Loading cached processed dataset at C:/Users/thoma/.cache/huggingface/datasets/pile-of-law___pile-of-law/r_legaladvice/0.0.0/acacf3e29a952ba9026148b979cb438151ebd33f842f5779a213967033c88619\\cache-5cf3a0e4382b5555.arrow\n"
     ]
    }
   ],
   "source": [
    "lm_datasets = tokenized_dataset.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48573f64-e23d-41a8-a342-12144e6d6bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    f\"opt125m-finetuned-pileoflaw_reddit\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,\n",
    "    save_strategy='epoch',\n",
    "    per_device_train_batch_size=12 \n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    eval_dataset=lm_datasets[\"validation\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96d5df51-0a70-4630-b7ea-70c81575d97e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\anaconda3\\envs\\hf\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 202713\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 12\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 12\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 50679\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50679' max='50679' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50679/50679 5:26:34, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.161900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.105100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>3.097400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.078400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>3.072100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.063100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>3.052000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>3.046700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>3.043200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>3.031200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>3.031800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>3.026400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>3.024700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>3.026000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>3.014300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>3.016600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>3.007400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>3.001100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>3.011100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>3.001800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>2.996300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>2.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>2.992500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>2.989800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>2.989700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>2.986900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>2.985300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>2.985200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>2.979400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>2.980500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>2.981300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>2.976300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>2.971000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>2.955700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>2.907500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>2.908800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>2.909700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>2.913500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>2.906200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>2.909700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>2.905900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>2.908100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>2.909400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>2.912000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>2.902900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>2.908300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>2.911500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>2.913500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>2.901700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>2.910200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>2.909500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>2.904500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>2.899100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>2.908900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>2.898600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>2.902600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>2.901800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>2.901200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>2.895000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>2.904500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>2.899400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>2.893700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>2.897100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>2.887600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>2.896500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>2.897200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33500</td>\n",
       "      <td>2.893900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>2.876000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34500</td>\n",
       "      <td>2.845200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>2.846700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35500</td>\n",
       "      <td>2.852200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>2.849700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36500</td>\n",
       "      <td>2.849800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>2.852500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37500</td>\n",
       "      <td>2.845800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>2.849100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38500</td>\n",
       "      <td>2.851800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>2.848800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39500</td>\n",
       "      <td>2.849200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>2.841200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40500</td>\n",
       "      <td>2.844200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>2.850700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41500</td>\n",
       "      <td>2.847100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>2.851100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42500</td>\n",
       "      <td>2.848300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43000</td>\n",
       "      <td>2.849000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43500</td>\n",
       "      <td>2.845500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>2.837700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44500</td>\n",
       "      <td>2.846000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>2.849100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45500</td>\n",
       "      <td>2.847800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>2.853500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46500</td>\n",
       "      <td>2.847700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47000</td>\n",
       "      <td>2.840600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47500</td>\n",
       "      <td>2.846300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>2.846100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48500</td>\n",
       "      <td>2.844700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49000</td>\n",
       "      <td>2.841800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49500</td>\n",
       "      <td>2.842700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>2.844800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50500</td>\n",
       "      <td>2.838200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to opt125m-finetuned-pileoflaw_reddit\\checkpoint-16893\n",
      "Configuration saved in opt125m-finetuned-pileoflaw_reddit\\checkpoint-16893\\config.json\n",
      "Model weights saved in opt125m-finetuned-pileoflaw_reddit\\checkpoint-16893\\pytorch_model.bin\n",
      "Saving model checkpoint to opt125m-finetuned-pileoflaw_reddit\\checkpoint-33786\n",
      "Configuration saved in opt125m-finetuned-pileoflaw_reddit\\checkpoint-33786\\config.json\n",
      "Model weights saved in opt125m-finetuned-pileoflaw_reddit\\checkpoint-33786\\pytorch_model.bin\n",
      "Saving model checkpoint to opt125m-finetuned-pileoflaw_reddit\\checkpoint-50679\n",
      "Configuration saved in opt125m-finetuned-pileoflaw_reddit\\checkpoint-50679\\config.json\n",
      "Model weights saved in opt125m-finetuned-pileoflaw_reddit\\checkpoint-50679\\pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=50679, training_loss=2.923679765575477, metrics={'train_runtime': 19596.794, 'train_samples_per_second': 31.033, 'train_steps_per_second': 2.586, 'total_flos': 7.9450937524224e+16, 'train_loss': 2.923679765575477, 'epoch': 3.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7804a5-c722-40ae-9826-3c9aff84532a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b36bd164-7832-488a-a49b-cb0204db2009",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"opt125m-finetuned-pileoflaw_reddit/checkpoint-50679\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd8efe3b-f8d1-454e-b92e-feabfc4faaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "generator = pipeline('text-generation',model=model,tokenizer=tokenizer, do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56046c8e-5cfb-4280-a4c9-a7f5526c8e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"\\nQuestion: My employer fired me today. Can I still receive severance?  \\nAnswer #1: Yes and no.  They fired you for not getting paid when you work more than 50 hours a week.  If that was true then they'd have been fired for missing too many paychecks or just working too many hours.\"}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"\\nQuestion: My employer fired me today. Can I still receive severance?  \\nAnswer #1:\",max_length=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0efa2e53-7cce-4a4b-8610-e0559ed166f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Token is required (write-access action) but no token found. You need to provide a token or be logged in to Hugging Face with `huggingface-cli login` or `notebook_login`. See https://huggingface.co/settings/tokens.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbettercallopt/opt_125m_legaladvice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hf\\lib\\site-packages\\transformers\\utils\\hub.py:779\u001b[0m, in \u001b[0;36mPushToHubMixin.push_to_hub\u001b[1;34m(self, repo_id, use_temp_dir, commit_message, private, use_auth_token, max_shard_size, create_pr, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    777\u001b[0m     working_dir \u001b[38;5;241m=\u001b[39m repo_id\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m--> 779\u001b[0m repo_id, token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_repo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprivate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprivate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morganization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morganization\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_temp_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    784\u001b[0m     use_temp_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(working_dir)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hf\\lib\\site-packages\\transformers\\utils\\hub.py:661\u001b[0m, in \u001b[0;36mPushToHubMixin._create_repo\u001b[1;34m(self, repo_id, private, use_auth_token, repo_url, organization)\u001b[0m\n\u001b[0;32m    658\u001b[0m         repo_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00morganization\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    660\u001b[0m token \u001b[38;5;241m=\u001b[39m HfFolder\u001b[38;5;241m.\u001b[39mget_token() \u001b[38;5;28;01mif\u001b[39;00m use_auth_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m use_auth_token\n\u001b[1;32m--> 661\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_repo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprivate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprivate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    663\u001b[0m \u001b[38;5;66;03m# If the namespace is not there, add it or `upload_file` will complain\u001b[39;00m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m repo_id \u001b[38;5;129;01mand\u001b[39;00m url \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHUGGINGFACE_CO_RESOLVE_ENDPOINT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hf\\lib\\site-packages\\huggingface_hub-0.10.1-py3.8.egg\\huggingface_hub\\utils\\_validators.py:94\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     92\u001b[0m         validate_repo_id(arg_value)\n\u001b[1;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hf\\lib\\site-packages\\huggingface_hub-0.10.1-py3.8.egg\\huggingface_hub\\utils\\_deprecation.py:31\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[0;32m     33\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[38;5;241m-\u001b[39mextra_args:])\n\u001b[0;32m     36\u001b[0m ]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hf\\lib\\site-packages\\huggingface_hub-0.10.1-py3.8.egg\\huggingface_hub\\hf_api.py:1652\u001b[0m, in \u001b[0;36mHfApi.create_repo\u001b[1;34m(self, repo_id, token, organization, private, repo_type, exist_ok, space_sdk, name)\u001b[0m\n\u001b[0;32m   1650\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_lfsmultipartthresh\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1651\u001b[0m     json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlfsmultipartthresh\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lfsmultipartthresh\n\u001b[1;32m-> 1652\u001b[0m headers \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_hf_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_write_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1653\u001b[0m r \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(path, headers\u001b[38;5;241m=\u001b[39mheaders, json\u001b[38;5;241m=\u001b[39mjson)\n\u001b[0;32m   1655\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hf\\lib\\site-packages\\huggingface_hub-0.10.1-py3.8.egg\\huggingface_hub\\utils\\_headers.py:116\u001b[0m, in \u001b[0;36mbuild_hf_headers\u001b[1;34m(use_auth_token, is_write_action, library_name, library_version, user_agent)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# Get auth token to send\u001b[39;00m\n\u001b[0;32m    115\u001b[0m token_to_send \u001b[38;5;241m=\u001b[39m get_token_to_send(use_auth_token)\n\u001b[1;32m--> 116\u001b[0m \u001b[43m_validate_token_to_send\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_to_send\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_write_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_write_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# Combine headers\u001b[39;00m\n\u001b[0;32m    119\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser-agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: _http_user_agent(\n\u001b[0;32m    121\u001b[0m         library_name\u001b[38;5;241m=\u001b[39mlibrary_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    124\u001b[0m     )\n\u001b[0;32m    125\u001b[0m }\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hf\\lib\\site-packages\\huggingface_hub-0.10.1-py3.8.egg\\huggingface_hub\\utils\\_headers.py:166\u001b[0m, in \u001b[0;36m_validate_token_to_send\u001b[1;34m(token, is_write_action)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_write_action:\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 166\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    167\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToken is required (write-access action) but no token found. You need\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    168\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to provide a token or be logged in to Hugging Face with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    169\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `huggingface-cli login` or `notebook_login`. See\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    170\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m https://huggingface.co/settings/tokens.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    171\u001b[0m         )\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m token\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_org\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    173\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    174\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must use your personal account token for write-access methods. To\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    175\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m generate a write-access token, go to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    176\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m https://huggingface.co/settings/tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    177\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: Token is required (write-access action) but no token found. You need to provide a token or be logged in to Hugging Face with `huggingface-cli login` or `notebook_login`. See https://huggingface.co/settings/tokens."
     ]
    }
   ],
   "source": [
    "model.push_to_hub('bettercallopt/opt_125m_legaladvice')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d08889-5f0a-4dd4-ae63-ba368662efdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c8a149-3ca2-4685-afc2-b27e9dd27c29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "hf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
