{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23646d82-1ade-42fe-8b7f-6084d0383966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import BloomTokenizerFast, BloomForCausalLM\n",
    "import torch\n",
    "import re\n",
    "import gradio as gr\n",
    "\n",
    "model_id = \"tomrb/bettercallbloom-3b\"\n",
    "tokenizer = BloomTokenizerFast.from_pretrained(model_id)\n",
    "model = BloomForCausalLM.from_pretrained(model_id,device_map=\"auto\")\n",
    "generator = pipeline('text-generation', model=model, tokenizer=tokenizer,do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7377697-5a14-4f08-ac99-bf3c1a242a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    #We add 'Question :' and 'Answer #1:' at the start and end of the prompt\n",
    "    return \"\\nQuestion: \" + text + \"\\nAnswer #1:\"\n",
    "\n",
    "def generate(text):\n",
    "    preprocessed_text = preprocess(text)\n",
    "    result = generator(preprocessed_text, max_length=128)\n",
    "    output = re.split(r'\\nQuestion:|Answer #1:|Answer #|Title:',result[0]['generated_text'])[2]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3ba381-99c1-4f92-ad3e-4634df43c937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "  gr.Markdown(\"<h1><center>Better Call Bloom!</center></h1>\")\n",
    "  gr.Markdown(\"\"\"<center>When in legal doubt, you better call BLOOM! Ask BLOOM any legal question:\n",
    "<img src=https://huggingface.co/spaces/tomrb/bettercallbloom/resolve/main/img.jpeg width=200px></center>\"\"\")\n",
    "  gr.Markdown(\"\"\"<center>***THIS IS NOT LEGAL ADVICE. Advice here is for informational purposes only and should not be considered final or official legal advice. See a local attorney for the best answer to your questions.***</center>\"\"\")\n",
    "  \n",
    "\n",
    "  input_text = gr.Textbox(label=\"Input\", lines=6)  \n",
    "  buton = gr.Button(\"Submit \")  \n",
    "  output_text = gr.Textbox(lines=6, label=\"Output\")\n",
    "  buton.click(generate, inputs=[input_text], outputs=output_text)  \n",
    "\n",
    "   \n",
    "  gr.HTML(\"\"\"\n",
    "    <div style=\"border-top: 1px solid #303030;\">\n",
    "      <br>\n",
    "      <p>Space by: <a href=\"https://twitter.com/TomRBeaudoin\"><img src=\"https://img.shields.io/twitter/follow/TomRBeaudoin?label=%40thomasrbeaudoin&style=social\" alt=\"Twitter Follow\"></a></p><br>\n",
    "      <p>Help me pay for GPU hours so I can publish faster models!</p>\n",
    "      <a href=\"https://www.buymeacoffee.com/thomasrb\" target=\"_blank\"><img src=\"https://cdn.buymeacoffee.com/buttons/v2/default-yellow.png\" alt=\"Buy Me A Coffee\" style=\"height: 45px !important;width: 162px !important;\" ></a><br><br>\n",
    "      <p><img src=\"https://visitor-badge.glitch.me/badge?page_id=tomrb.bettercallbloom\" alt=\"visitors\"></p>\n",
    "    </div>\n",
    "    \"\"\")\n",
    "demo.launch(enable_queue=True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225fb113-591b-4d5f-bf54-562d67292515",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf_cpu",
   "language": "python",
   "name": "hf_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
